setwd("C:/Users/thoma/OneDrive/Bureau/Ecole/ESIR2/Semestre8/ACI/TP/R")
install.packages("tensorflow")
install.packages("keras")
library(tensorflow)
library(keras)
source("./fonctions_utiles.R")
model <- keras_model_sequential()
model %>%
layer_dense(units = 80, input_shape =19, activation = 'relu') %>%
layer_dense(units = 40, activation = 'relu') %>%
layer_dense(units = 30, activation = 'relu') %>%
layer_dense(units = 7,activation = 'softmax')
history <- model %>% compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = c('accuracy'))
model %>% fit(train_x, train_y, epochs = 500, batch.size = 10, validation_split = 0.2,callbacks = list(callback_early_stopping("val_loss", patience = 100)),view_metrics = F)
dataset = read.table("./data/segment.dat")
# SÃ©paration Apprentissage/Test, classique
nall = nrow(dataset) #total number of rows in data
nall
ntrain = floor(0.80 * nall) # number of rows for train: 80%
ntrain
ntest = floor(0.20* nall) # number of rows for test: 20%
ntest
index = sample(nall) # permutation alÃ©atoire des nombres 1, 2, 3 , ... nall
index
train_x = dataset[index[1:ntrain],1:19] # ensemble d'apprentisssage
train_labels = dataset[index[1:ntrain],20] # labels d'apprentissage
test_x = dataset[index[(ntrain+1):nall],1:19] # ensemble de test
test_labels = dataset[index[(ntrain+1):nall],20] # labels de test
train_x = matrix(unlist(train_x), ncol = 19)
test_x = matrix(unlist(test_x), ncol = 19)
table(train_labels)
# Vous observez que la classe est un entier entre 1 et 7.
# Pour keras, il faut que les labels des classes commencent Ã  zÃ©ro
# On va donc soustraire 1 Ã  train_labels et test_labels, et creer train_y et test_y:
train_y = train_labels-1
test_y = test_labels-1
# Puis il faut transformer ces vecteurs pour qu'ils soient au bon format attendu par keras :
# pour chaque individu, il faut un vecteur de taille 7 (nb de classes) oÃ¹ tous les
# composants sont Ã  0 sauf celui qui correspond Ã  la classe de l'individu.
# Par exemple, pour un individu de classe 3, ce vecteur doit etre 0 0 0 1 0 0 0 (un 1 pour la classe 3, et 0 pour les autres)
# Ceci est fait par la commande :
train_y = to_categorical(train_y)
test_y = to_categorical(test_y)
model <- keras_model_sequential()
model %>%
layer_dense(units = 80, input_shape =19, activation = 'relu') %>%
layer_dense(units = 40, activation = 'relu') %>%
layer_dense(units = 30, activation = 'relu') %>%
layer_dense(units = 7,activation = 'softmax')
history <- model %>% compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = c('accuracy'))
model %>% fit(train_x, train_y, epochs = 500, batch.size = 10, validation_split = 0.2,callbacks = list(callback_early_stopping("val_loss", patience = 100)),view_metrics = F)
plot_NN_loss(history)
plot_NN_accuracy(history)
model <- keras_model_sequential()
model %>%
layer_dense(units = 80, input_shape =19, activation = 'relu') %>%
layer_dense(units = 40, activation = 'relu') %>%
layer_dense(units = 30, activation = 'relu') %>%
layer_dense(units = 7,activation = 'softmax')
model %>% compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = c('accuracy'))
history <-model %>% fit(train_x, train_y, epochs = 500, batch.size = 10, validation_split = 0.2,callbacks = list(callback_early_stopping("val_loss", patience = 100)),view_metrics = F)
plot_NN_loss(history)
plot_NN_accuracy(history)
### Une fois le modÃ¨le appris (dans la variable model par exemple), appelez la commande 'predict' pour obtenir la sortie du reseau pour les exemples de l'ensemble de test.
###### Question 3: quelle est la forme de la prediction pour un exemple ? Quelle est la classe associÃ©e a chaque exemple ?
predict(model, test_x)
model%>%evaluate(test_x,test_y)
model%>%evaluate(train_x,train_y)
